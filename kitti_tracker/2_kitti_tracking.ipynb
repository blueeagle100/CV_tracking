{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itberrios/CV_tracking/blob/main/kitti_tracker/2_kitti_tracking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRjlA-8T-pOQ"
      },
      "source": [
        "# **KITTI Tracking**\n",
        "\n",
        "In this tutorial we will learn how to track objects in 3D on the KITTI dataset. We will build off of our object dector from part 1 and use each obejct detection to update the tracks.\n",
        "\n",
        "For more information a readme for the KITTI data can be found [here](https://github.com/yanii/kitti-pcl/blob/master/KITTI_README.TXT), and a paper that details the data collection and coordinate systems can be found [here](http://www.cvlibs.net/publications/Geiger2013IJRR.pdf). \n",
        "\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get the data"
      ],
      "metadata": {
        "id": "b8BfTqJ7_BXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://s3.eu-central-1.amazonaws.com/avg-kitti/raw_data/2011_10_03_drive_0047/2011_10_03_drive_0047_sync.zip"
      ],
      "metadata": {
        "id": "K69AK4e7_FOl",
        "outputId": "651b6267-a956-47eb-8a91-1086c01fc367",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-22 11:48:55--  https://s3.eu-central-1.amazonaws.com/avg-kitti/raw_data/2011_10_03_drive_0047/2011_10_03_drive_0047_sync.zip\n",
            "Resolving s3.eu-central-1.amazonaws.com (s3.eu-central-1.amazonaws.com)... 52.219.171.13\n",
            "Connecting to s3.eu-central-1.amazonaws.com (s3.eu-central-1.amazonaws.com)|52.219.171.13|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3103291675 (2.9G) [application/zip]\n",
            "Saving to: ‘2011_10_03_drive_0047_sync.zip’\n",
            "\n",
            "2011_10_03_drive_00 100%[===================>]   2.89G  28.8MB/s    in 1m 43s  \n",
            "\n",
            "2022-09-22 11:50:39 (28.6 MB/s) - ‘2011_10_03_drive_0047_sync.zip’ saved [3103291675/3103291675]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://s3.eu-central-1.amazonaws.com/avg-kitti/raw_data/2011_10_03_calib.zip"
      ],
      "metadata": {
        "id": "CC3a9bNg_C2S",
        "outputId": "297b344c-75e6-44be-85b6-cf9d489e8324",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-22 11:50:39--  https://s3.eu-central-1.amazonaws.com/avg-kitti/raw_data/2011_10_03_calib.zip\n",
            "Resolving s3.eu-central-1.amazonaws.com (s3.eu-central-1.amazonaws.com)... 52.219.46.23\n",
            "Connecting to s3.eu-central-1.amazonaws.com (s3.eu-central-1.amazonaws.com)|52.219.46.23|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4075 (4.0K) [application/zip]\n",
            "Saving to: ‘2011_10_03_calib.zip’\n",
            "\n",
            "2011_10_03_calib.zi 100%[===================>]   3.98K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-09-22 11:50:40 (192 MB/s) - ‘2011_10_03_calib.zip’ saved [4075/4075]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!jar xf 2011_10_03_drive_0047_sync.zip\n",
        "!jar xf 2011_10_03_calib.zip"
      ],
      "metadata": {
        "id": "FnayIl6N_HrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Base Library Import"
      ],
      "metadata": {
        "id": "lXqKyrfp_Jh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from glob import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams[\"figure.figsize\"] = (20, 10)"
      ],
      "metadata": {
        "id": "lgM4JrRc_I-h"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Utility functions"
      ],
      "metadata": {
        "id": "lMDnx_XP_ON7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/itberrios/CV_tracking/raw/main/kitti_tracker/kitti_utils.py\n",
        "from kitti_utils import *"
      ],
      "metadata": {
        "id": "gs5psD0dRRJN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!wget https://github.com/itberrios/CV_tracking/raw/main/kitti_tracker/kitti_detection_utils.py\n",
        "from kitti_detection_utils import *"
      ],
      "metadata": {
        "id": "oK9MoM5o_MNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Data Paths"
      ],
      "metadata": {
        "id": "OwE2dxKP_WAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = r'2011_10_03/2011_10_03_drive_0047_sync'\n",
        "\n",
        "# get RGB camera data\n",
        "left_image_paths = sorted(glob(os.path.join(DATA_PATH, 'image_02/data/*.png')))\n",
        "right_image_paths = sorted(glob(os.path.join(DATA_PATH, 'image_03/data/*.png')))\n",
        "\n",
        "# get LiDAR data\n",
        "bin_paths = sorted(glob(os.path.join(DATA_PATH, 'velodyne_points/data/*.bin')))\n",
        "\n",
        "# get GPS/IMU data\n",
        "oxts_paths = sorted(glob(os.path.join(DATA_PATH, r'oxts/data**/*.txt')))\n",
        "\n",
        "print(f\"Number of left images: {len(left_image_paths)}\")\n",
        "print(f\"Number of right images: {len(right_image_paths)}\")\n",
        "print(f\"Number of LiDAR point clouds: {len(bin_paths)}\")\n",
        "print(f\"Number of GPS/IMU frames: {len(oxts_paths)}\")"
      ],
      "metadata": {
        "id": "XDH7Nhn5_Vdd",
        "outputId": "0a908f66-f484-4425-b4f6-e9e47a2b8b69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of left images: 837\n",
            "Number of right images: 837\n",
            "Number of LiDAR point clouds: 837\n",
            "Number of GPS/IMU frames: 837\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Camera Transformation Matrices"
      ],
      "metadata": {
        "id": "EYRASHTc_a-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('2011_10_03/calib_cam_to_cam.txt','r') as f:\n",
        "    calib = f.readlines()\n",
        "\n",
        "# get projection matrices (rectified left camera --> left camera (u,v,z))\n",
        "P_rect2_cam2 = np.array([float(x) for x in calib[25].strip().split(' ')[1:]]).reshape((3,4))\n",
        "\n",
        "\n",
        "# get rectified rotation matrices (left camera --> rectified left camera)\n",
        "R_ref0_rect2 = np.array([float(x) for x in calib[24].strip().split(' ')[1:]]).reshape((3, 3,))\n",
        "\n",
        "# add (0,0,0) translation and convert to homogeneous coordinates\n",
        "R_ref0_rect2 = np.insert(R_ref0_rect2, 3, values=[0,0,0], axis=0)\n",
        "R_ref0_rect2 = np.insert(R_ref0_rect2, 3, values=[0,0,0,1], axis=1)\n",
        "\n",
        "\n",
        "# get rigid transformation from Camera 0 (ref) to Camera 2\n",
        "R_2 = np.array([float(x) for x in calib[21].strip().split(' ')[1:]]).reshape((3,3))\n",
        "t_2 = np.array([float(x) for x in calib[22].strip().split(' ')[1:]]).reshape((3,1))\n",
        "\n",
        "# get cam0 to cam2 rigid body transformation in homogeneous coordinates\n",
        "T_ref0_ref2 = np.insert(np.hstack((R_2, t_2)), 3, values=[0,0,0,1], axis=0)"
      ],
      "metadata": {
        "id": "FxmHiWjH_ZqT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get LiDAR and IMU Transformation matrices"
      ],
      "metadata": {
        "id": "Ymr3IGeH_kuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "T_velo_ref0 = get_rigid_transformation(r'2011_10_03/calib_velo_to_cam.txt')\n",
        "T_imu_velo = get_rigid_transformation(r'2011_10_03/calib_imu_to_velo.txt')"
      ],
      "metadata": {
        "id": "cRlNyw53_j5t"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Get LiDAR ⬌ Camera2 Rotation matrices\n",
        "\n",
        "LiDAR &rarr; Cam Ref 0 &rarr; Cam Ref 2 &rarr; Rectified 2 &rarr; Camera 2"
      ],
      "metadata": {
        "id": "Vz-T9MBnAjsq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# transform from velo (LiDAR) to left color camera (shape 3x4)\n",
        "T_velo_cam2 = P_rect2_cam2 @ R_ref0_rect2 @ T_ref0_ref2 @ T_velo_ref0 \n",
        "\n",
        "# homogeneous transform from left color camera to velo (LiDAR) (shape: 4x4)\n",
        "T_cam2_velo = np.linalg.inv(np.insert(T_velo_cam2, 3, values=[0,0,0,1], axis=0)) "
      ],
      "metadata": {
        "id": "ba_C6VjVAX1i"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Get IMU ⬌ Camera2 Rotation matrices\n",
        "\n",
        "IMU &rarr; LiDAR &rarr; Cam Ref 0 &rarr; Cam Ref 2 &rarr; Rectified 2 &rarr; Camera 2"
      ],
      "metadata": {
        "id": "nJcbv-AxBJxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# transform from IMU to left color camera (shape 3x4)\n",
        "T_imu_cam2 = T_velo_cam2 @ T_imu_velo\n",
        "\n",
        "# homogeneous transform from left color camera to IMU (shape: 4x4)\n",
        "T_cam2_imu = np.linalg.inv(np.insert(T_imu_cam2, 3, values=[0,0,0,1], axis=0)) "
      ],
      "metadata": {
        "id": "che3QAEjAhkZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Get Object Detection pipeline**"
      ],
      "metadata": {
        "id": "1ptISKMrBxP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5"
      ],
      "metadata": {
        "id": "uagV1pAQAi0N",
        "outputId": "fa8358dd-938c-46a8-8a67-253e4e91813d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'yolov5' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r yolov5/requirements.txt  #Install whatever is needed"
      ],
      "metadata": {
        "id": "H36aVY1HB5rk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')  # or yolov5m, yolov5l, yolov5x, custom"
      ],
      "metadata": {
        "id": "bzz2r4qgB7SL",
        "outputId": "f882a177-7698-49ce-8748-4f5a18e687fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2022-9-22 Python-3.7.14 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
            "Adding AutoShape... \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set confidence and IOU thresholds\n",
        "model.conf = 0.25  # confidence threshold (0-1), default: 0.25\n",
        "model.iou = 0.25  # NMS IoU threshold (0-1), default: 0.45"
      ],
      "metadata": {
        "id": "eX4ENFYUB9aA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Set up tracking pipeline**\n",
        "\n",
        "The tracking will be a 3D real world extension of the [SORT algorithm](https://arxiv.org/pdf/1602.00763.pdf). Instead of tracking bounding box location and aspect, we will simple track the (x, y, z) locations of each detected object. Even though we can esily neglect the z-axis, we will include it to keep our coordinate trasnformations easier. In our Kalman Filter we will use a constanct velocity model with a random accleration assumption.\n",
        "\n",
        "The tracking pipeline will use the object detection methods from part 1 as a backbone. The L2 distance between object (x,y,z) centers will be used as a cost. The Hungarian Algorithm (linear_sum_assignemnt in Python) will be used to match old tracks with new updates and determine if tracks are not updated."
      ],
      "metadata": {
        "id": "b3lqvIn4Gq9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.optimize import linear_sum_assignment\n",
        "\n",
        "# helper functions\n",
        "def total_cost(center1, center2):\n",
        "    ''' Return L2 distance between object centers '''\n",
        "    return np.linalg.norm(center1 - center2)\n",
        "\n",
        "\n",
        "def associate(old_centers, new_centers, dist_thresh=1):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "        old_centers - former center locations (at time 0)\n",
        "        new_centers - new center locations (at time 1)\n",
        "        dist_thresh - distance threshold to declare tracks matched or unmatched\n",
        "    Outputs:\n",
        "       matches - Matched tracks\n",
        "       unmatched_detections - Unmatched Detections\n",
        "       unmatched_trackers - Unmatched Tracks\n",
        "\n",
        "    \"\"\"\n",
        "    if (len(new_centers) == 0) and (len(old_centers) == 0):\n",
        "        return [], [], []\n",
        "    elif(len(old_centers)==0):\n",
        "        return [], new_centers, []\n",
        "    elif(len(new_centers)==0):\n",
        "        return [], [], old_centers\n",
        "\n",
        "    # distances will store L2 distances between object centers\n",
        "    distances = np.zeros((len(old_centers),len(new_centers)),dtype=np.float32)\n",
        "\n",
        "    # Go through centers and store the L2 distances between all of them\n",
        "    for i,old_cntr in enumerate(old_centers):\n",
        "        for j,new_cntr in enumerate(new_centers):\n",
        "            distances[i][j] = total_cost(old_cntr, new_cntr)\n",
        "\n",
        "\n",
        "    # Hungarian Algorithm (with L2 distance metric as the cost)\n",
        "    row_ind, col_ind = linear_sum_assignment(distances)\n",
        "    hungarian_matrix = np.array(list(zip(row_ind, col_ind)))\n",
        "\n",
        "    # Create new unmatched lists for old and new boxes\n",
        "    matches, unmatched_detections, unmatched_tracks = [], [], []\n",
        "\n",
        "    # Go through the Hungarian Matrix, if matched element has dist <= threshold (0.3), add it to the unmatched \n",
        "    # Else: add the match    \n",
        "    for h in hungarian_matrix:\n",
        "        if(distances[h[0],h[1]] > dist_thresh):\n",
        "            unmatched_tracks.append(old_centers[h[0]])\n",
        "            unmatched_detections.append(new_centers[h[1]])\n",
        "        else:\n",
        "            matches.append(h.reshape(1,2))\n",
        "\n",
        "    if(len(matches)==0):\n",
        "        matches = np.empty((0,2), dtype=int)\n",
        "    else:\n",
        "        matches = np.concatenate(matches, axis=0)\n",
        "\n",
        "    # Go through old centers, if no matched detection, add it to the unmatched_old_centers\n",
        "    for t, trk in enumerate(old_centers):\n",
        "        if(t not in hungarian_matrix[:,0]):\n",
        "            unmatched_tracks.append(trk)\n",
        "\n",
        "    # Go through new boxes, if no matched tracking, add it to the unmatched_new_centers\n",
        "    for d, det in enumerate(new_centers):\n",
        "        if(d not in hungarian_matrix[:,1]):\n",
        "            unmatched_detections.append(det)\n",
        "\n",
        "    return matches, unmatched_detections, unmatched_tracks\n",
        "  "
      ],
      "metadata": {
        "id": "X5Wpx6tGB-6Q"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test track pipeline"
      ],
      "metadata": {
        "id": "zzC9xhsCLPdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index1 = 20\n",
        "index2 = 21\n",
        "index3 = 22\n",
        "index4 = 23\n",
        "\n",
        "left_image_1 = cv2.cvtColor(cv2.imread(left_image_paths[index1]), cv2.COLOR_BGR2RGB)\n",
        "bin_path_1 = bin_paths[index1]\n",
        "\n",
        "left_image_2 = cv2.cvtColor(cv2.imread(left_image_paths[index2]), cv2.COLOR_BGR2RGB)\n",
        "bin_path_2 = bin_paths[index2]\n",
        "\n",
        "left_image_3 = cv2.cvtColor(cv2.imread(left_image_paths[index3]), cv2.COLOR_BGR2RGB)\n",
        "bin_path_3 = bin_paths[index3]\n",
        "\n",
        "left_image_4 = cv2.cvtColor(cv2.imread(left_image_paths[index4]), cv2.COLOR_BGR2RGB)\n",
        "bin_path_4 = bin_paths[index2]"
      ],
      "metadata": {
        "id": "od43lebwGg4G"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imu_xyz_1 = get_imu_xyz(left_image_1, bin_path_1, model, T_velo_cam2, T_cam2_imu)"
      ],
      "metadata": {
        "id": "xkzA6C_ULRNF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imu_xyz_2 = get_imu_xyz(left_image_2, bin_path_2, model, T_velo_cam2, T_cam2_imu)"
      ],
      "metadata": {
        "id": "OMNNmyA5SDn7"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imu_xyz_3 = get_imu_xyz(left_image_3, bin_path_3, model, T_velo_cam2, T_cam2_imu)\n",
        "imu_xyz_4 = get_imu_xyz(left_image_4, bin_path_4, model, T_velo_cam2, T_cam2_imu)"
      ],
      "metadata": {
        "id": "JdYKc5gyoMbl"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imu_xyz_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nbwM4-SSGsE",
        "outputId": "77767e1f-9b6e-41a8-f797-c133fbc47e99"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[     11.911,      -2.722,    -0.16906],\n",
              "       [     15.574,       7.346,    -0.16672],\n",
              "       [     11.089,      3.1335,    -0.13419],\n",
              "       [     23.339,     -2.8507,   -0.010265],\n",
              "       [     22.384,      3.5784,   -0.070647],\n",
              "       [     46.072,      0.4007,     0.27154],\n",
              "       [     29.946,      3.2677,   -0.044347],\n",
              "       [     56.769,     -2.0642,     0.13642],\n",
              "       [     13.094,      2.8895,     0.36942],\n",
              "       [     52.366,      4.0757,     0.11331],\n",
              "       [     45.877,     -3.0317,   0.0097941],\n",
              "       [     23.318,      2.8036,   -0.096056]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imu_xyz_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVr5qwC1SH_r",
        "outputId": "ee590a5f-cbc4-4a5a-811e-4063d0297129"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[     15.315,       7.299,     -0.1505],\n",
              "       [     11.965,      -2.751,    -0.10473],\n",
              "       [     11.027,      3.1306,    -0.12802],\n",
              "       [      23.49,     -2.8317,   -0.016854],\n",
              "       [     22.356,      3.6084,   -0.070034],\n",
              "       [     29.881,      3.2596,   -0.042096],\n",
              "       [     57.115,     -1.8578,    -0.26439],\n",
              "       [     46.409,     0.33389,     0.26685],\n",
              "       [     52.351,      3.9927,     0.11557],\n",
              "       [     31.399,      7.6322,    -0.18401],\n",
              "       [     46.348,     -3.0605, -0.00073378]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matches, unmatched_detections, unmatched_tracks = associate([], imu_xyz_2, dist_thresh=1)"
      ],
      "metadata": {
        "id": "oJ9FmUZISI4N"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matches"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEgNcuESSfwo",
        "outputId": "82d63ac2-685b-4690-d5d6-421350a8d687"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imu_xyz_2[matches[:, 1]]"
      ],
      "metadata": {
        "id": "Y_qv1ZUMa9Pp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unmatched_detections"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_h32f9ISgXg",
        "outputId": "2364e95d-1633-4595-ecdd-ea279f476c22"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[     15.315,       7.299,     -0.1505],\n",
              "       [     11.965,      -2.751,    -0.10473],\n",
              "       [     11.027,      3.1306,    -0.12802],\n",
              "       [      23.49,     -2.8317,   -0.016854],\n",
              "       [     22.356,      3.6084,   -0.070034],\n",
              "       [     29.881,      3.2596,   -0.042096],\n",
              "       [     57.115,     -1.8578,    -0.26439],\n",
              "       [     46.409,     0.33389,     0.26685],\n",
              "       [     52.351,      3.9927,     0.11557],\n",
              "       [     31.399,      7.6322,    -0.18401],\n",
              "       [     46.348,     -3.0605, -0.00073378]])"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unmatched_tracks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xfant_T1SrQt",
        "outputId": "f8d1c80d-acfa-4d94-bec2-322b8bb97595"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_color(idx):\n",
        "    '''returns a random color seeded from the input index '''\n",
        "    blue = idx*3 % 256\n",
        "    green = idx*15 % 256\n",
        "    red = idx*25 % 256\n",
        "    return (red, green, blue)\n",
        "\n",
        "# track params\n",
        "class Track():\n",
        "    def __init__(self, idx, xyz, color, cat=0, kf=None, age=1, unmatched_age=0, \n",
        "                 hit_streak=0, fov=0):\n",
        "        ''' \n",
        "          idx - track index\n",
        "          xyz - track center in IMU (x, y, z) coordinates\n",
        "          color - color for the object and it's bounding box\n",
        "          cat - track category\n",
        "          kf - KalmanFilter Object for tracking\n",
        "          age - track age, number of frames track has been observed\n",
        "          hit_streak - simultaneuos hits\n",
        "          unmatched_age - number of frames track has not been observed\n",
        "          fov - (_Bool) indicates that the object is approaching edge of FOV\n",
        "          '''\n",
        "          \n",
        "        self.idx = idx\n",
        "        self.xyz = xyz\n",
        "        self.color = color\n",
        "        self.cat = cat\n",
        "        self.kf = kf\n",
        "        self.age = age\n",
        "        self.hit_streak = hit_streak\n",
        "        self.unmatched_age = unmatched_age\n",
        "\n",
        "    def update(self, new_xyz):\n",
        "        ''' Update function for a given track object '''\n",
        "\n",
        "        # update position with Kalman Filter\n",
        "        # TBD\n",
        "        # track.kf.update() ?? find a quick way to do this\n",
        "\n",
        "        # move bounding box\n",
        "        # TBD find a good way to do this\n",
        "        \n",
        "        # update with new measurement (TEMP without Kalman Filter)\n",
        "        self.xyz = new_xyz\n",
        "\n",
        "        # update Kalman Filter State with new obs\n",
        "        # TBD\n",
        "        # self.kf.update(new_xyz)\n",
        "\n",
        "        # update age\n",
        "        self.age += 1\n",
        "\n"
      ],
      "metadata": {
        "id": "tbW0M4cSbZqm"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tracker params\n",
        "MIN_HIT_STREAK = 1\n",
        "MAX_UNMATCHED_AGE = 2\n",
        "\n",
        "class Tracker():\n",
        "    def __init__(self,  max_age=1, min_hits=3, dist_threshold=1):\n",
        "        ''' max_age - maximum number of updates for a track to be declared lost\n",
        "            min_hits - minimum number of hits/matches for a track to be delcared\n",
        "            dist_threshold - minimum L2 distance for a track to be considered\n",
        "            '''\n",
        "        self.max_age = max_age\n",
        "        self.min_hits = min_hits\n",
        "        self.dist_threshold = dist_threshold\n",
        "        self.tracks = []\n",
        "        self.track_idx = 0 # unique track index\n",
        "        self.frame_count = 0 # frames \n",
        "    \n",
        "    def update(self, detections):\n",
        "        ''' Update the tracks with new detections \n",
        "            Inputs: detections - Nx3 array of (x, y, z) object locations\n",
        "            Outputs: new_tracks - list of new track objects that are filtered\n",
        "                out based on min hits required for a track to be shown\n",
        "            '''\n",
        "        # increment frame count\n",
        "        self.frame_count += 1\n",
        "        \n",
        "        # get track centers for association\n",
        "        tracks_xyz = [trk.xyz for trk in self.tracks]\n",
        "        \n",
        "        # associate new detections with current tracks (Hungarian)\n",
        "        matches, unmatched_dets, unmatched_trks = associate(tracks_xyz,\n",
        "                                                            detections, \n",
        "                                                            self.dist_threshold)\n",
        "        \n",
        "        # get new tracks list\n",
        "        new_tracks = []\n",
        "\n",
        "        # update matches\n",
        "        for match in matches:\n",
        "\n",
        "            new_xyz = detections[match[0]]\n",
        "\n",
        "            # update track\n",
        "            self.tracks[match[1]].update(new_xyz)\n",
        "\n",
        "            # update hit streak\n",
        "            self.tracks[match[1]].hit_streak += 1\n",
        "\n",
        "            # add to new tracks\n",
        "            if self.tracks[match[1]].hit_streak >= self.min_hits:\n",
        "                new_tracks.append(self.tracks[match[1]])\n",
        "\n",
        "\n",
        "        # handle unmatched observations\n",
        "        for old_xyz in unmatched_trks:\n",
        "\n",
        "            print(old_xyz)\n",
        "            print(tracks_xyz)\n",
        "\n",
        "            print(np.where(tracks_xyz == old_xyz))\n",
        "\n",
        "            # get old track index \n",
        "            trk_idx = np.where(tracks_xyz == old_xyz)[0][0]\n",
        "            print(trk_idx)\n",
        "\n",
        "            print(tracks_xyz.index(old_xyz))\n",
        "\n",
        "            # increment age\n",
        "            self.tracks[tracks_xyz.index(old_xyz)].age += 1\n",
        "\n",
        "            # if track age too large, then remove it\n",
        "            if self.tracks[tracks_xyz.index(old_xyz)].age > self.max_age:\n",
        "                del self.tracks[tracks_xyz.index(old_xyz)]\n",
        "            else:\n",
        "\n",
        "                # # get predicted state from previous data\n",
        "                # obs.kf.predict()\n",
        "\n",
        "                # # move box to newly predicted location for next iteration\n",
        "                # obs.box = move_box(obs.box, obs.kf.x[0], obs.kf.x[2]) \n",
        "\n",
        "                # obs.unmatched_age += 1\n",
        "\n",
        "                # # determine if object is in FOV\n",
        "                # obs.fov = detect_fov(obs.box)\n",
        "\n",
        "                # add to new tracks\n",
        "                new_tracks.append(self.tracks[tracks_xyz.index(old_xyz)])\n",
        "\n",
        "\n",
        "        # get new observations\n",
        "        for new_xyz in unmatched_dets:\n",
        "\n",
        "            # # cat = categories[out_boxes.index(new_obs)]\n",
        "\n",
        "            # # cat = categories[np.where(out_boxes == new_obs)[0][0]] # only if using arrays\n",
        "            # obs = Obstacle(idx, new_obs, constantVelocity_KF(R_std_v, Q_std_v, dt_v), \n",
        "            #               cat=cat, age=0, unmatched_age=0)\n",
        "            \n",
        "            # get new track\n",
        "            color = get_color(self.track_idx)\n",
        "            track = Track(self.track_idx, new_xyz, color)\n",
        "\n",
        "            \n",
        "            # # get initial Kalman Filter Prediction\n",
        "            # track.kf.predict()\n",
        "            # # update first Kalman Filter State with observation\n",
        "            # track.kf.update(new_xyz)\n",
        "\n",
        "            # # move box to newly predicted location for next iteration\n",
        "            # # obs.box = move_box(new_obs, obs.kf.x[0], obs.kf.x[2]) \n",
        "\n",
        "            # or just do this\n",
        "            # track.update(new_xyz)\n",
        "\n",
        "            # # or just use initial measurement for first box position\n",
        "\n",
        "            # new_obstacles.append(obs)\n",
        "\n",
        "            # incerement unique track indexes\n",
        "            self.track_idx += 1\n",
        "\n",
        "            # add to tracks list\n",
        "            self.tracks.append(track)\n",
        "\n",
        "        return new_tracks\n",
        "\n",
        "    def seed(self, detections):\n",
        "        ''' seeds the tracker with initial detections '''\n",
        "        pass"
      ],
      "metadata": {
        "id": "hJzdVYPDTsUb"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initiate the tracker\n",
        "tracker = Tracker(max_age=2, min_hits=1, dist_threshold=1)"
      ],
      "metadata": {
        "id": "I2ndBa-dk-1i"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seed tracker with first set of detections\n",
        "tracker.update(imu_xyz_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZE2wpzQVlGzm",
        "outputId": "c425300f-9357-439f-a418-e0244fc25ad9"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get next track update\n",
        "tracker.update(imu_xyz_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "GWyE35HHp5sm",
        "outputId": "c90c7bb5-e504-47b8-8a4f-69b8376f0142"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[     23.318      2.8036   -0.096056]\n",
            "[array([     11.911,      -2.722,    -0.16906]), array([     15.574,       7.346,    -0.16672]), array([     11.089,      3.1335,    -0.13419]), array([     23.339,     -2.8507,   -0.010265]), array([     22.384,      3.5784,   -0.070647]), array([     46.072,      0.4007,     0.27154]), array([     29.946,      3.2677,   -0.044347]), array([     56.769,     -2.0642,     0.13642]), array([     13.094,      2.8895,     0.36942]), array([     52.366,      4.0757,     0.11331]), array([     45.877,     -3.0317,   0.0097941]), array([     23.318,      2.8036,   -0.096056])]\n",
            "(array([11, 11, 11]), array([0, 1, 2]))\n",
            "11\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-185-f38ae7b4d434>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# get next track update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimu_xyz_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-182-9cf403589f23>\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, detections)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrk_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtracks_xyz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_xyz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# increment age\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tai3q5srp_EE"
      },
      "execution_count": 176,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.7.8 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.8"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "0a54084e6b208ee8d1ce3989ffc20924477a5f55f5a43e22e699a6741623861e"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}