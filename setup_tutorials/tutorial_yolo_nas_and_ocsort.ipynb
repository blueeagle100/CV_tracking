{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOw8VN0rqZQOqV5TpCGZ4pW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itberrios/CV_tracking/blob/main/setup_tutorials/tutorial_yolo_nas_and_ocsort.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **YOLO-NAS + OC-SORT**\n",
        "\n",
        "This notebook contains a tutorial that shows how to incorporate YOLO-NAS with OC-SORT to perform real time visual tracking on a data stream. In this case, we will use a YouTube video to simulate a data stream of image frames.\n",
        "\n",
        "## **YOLO-NAS**\n",
        "[YOLO-NAS](https://github.com/Deci-AI/super-gradients/blob/master/YOLONAS.md) is a powerful object detector with an optimal neural network architecture that has been selected using Neural Architecture Search (NAS), hence the name NAS. \n",
        "\n",
        "At the time of release, it outperforms all of the other single shot object detectos in terms of speed and accuracy. It also excels in an area that most single shot detector struggle with, small objects. Two-stage detectors typically perform better than single stage detectors on small objects, at the cost of increased detection time [source](https://arxiv.org/pdf/1907.09408.pdf). YOLO-NAS, howver seems to provide a good tradeoff between detection speed and accuracy on small objects that previous versions of YOLO have not been able to deliver.\n",
        "\n",
        "## **OC-SORT**\n",
        "[OC-SORT](https://arxiv.org/abs/2203.14360) is a robust visual obejct tracking algorithm that improves upon the already popular [SORT](https://arxiv.org/abs/1602.00763) algorithm.\n",
        "\n",
        "SORT tends to loose track on obejcts when they are lost for extended periods of time or when non-linear motion occurs. Algorithms such as Deep SORT have effectoively improved SORT in these scenarios with a Deep Association metric that is computed with a [Siamese Neural Network](https://arxiv.org/pdf/1707.02131.pdf) over the image patches. Eventhough this is effective it comes with the cost of increased detection time due to the deep association and the Siamese network needs to be trained on in-domain data for this approach to be effective. OC-SORT on the otherhand is able to effectively increase tracking performance in a model free fashion with minimal impact to inference speed.\n",
        "\n",
        "OC-SORT introduces\n",
        "- Observation Centric Re-Update (ORU)\n",
        "    - Reduces accumulated Kalman Filter error/uncertainty when a lost track is re-associated\n",
        "- Observation Centric Momentum (OCM)\n",
        "    - Uses previous observations to compute a low noise expected motion direction and incorporates it into the track association cost\n",
        "- Observation Centric Recovery (OCR)\n",
        "    - Uses the last known observation as a secondary association to help prevent lost tracks\n",
        "\n",
        "For more details and a break down of each technique that OC-SORT introduces, please see this [article](https://medium.com/@itberrios6/introduction-to-ocsort-c1ea1c6adfa2)."
      ],
      "metadata": {
        "id": "3KMFMnBdToro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Install Libraries"
      ],
      "metadata": {
        "id": "OlhbIxdPUBDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sketchy fix for \"https://stackoverflow.com/questions/73711994/importerror-cannot-import-name-is-directory-from-pil-util-usr-local-lib\"\n",
        "!pip install fastcore -U"
      ],
      "metadata": {
        "id": "1bWrvYHJcItP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# supergradients installs\n",
        "! pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0 --extra-index-url https://download.pytorch.org/whl/cu113 &> /dev/null\n",
        "! pip install super-gradients\n",
        "! pip install pytorch-quantization==2.1.2 --extra-index-url https://pypi.ngc.nvidia.com &> /dev/null\n",
        "! pip install matplotlib==3.1.3 &> /dev/null\n",
        "! pip install --upgrade psutil==5.9.2 &> /dev/null\n",
        "! pip install --upgrade pillow==7.1.2 &> /dev/null"
      ],
      "metadata": {
        "id": "6I-qMzr9xeIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcOJRYPVTkeX"
      },
      "outputs": [],
      "source": [
        "!pip install filterpy\n",
        "!pip install pytube\n",
        "!pip install moviepy\n",
        "!pip install ffmpeg\n",
        "\n",
        "# bug fix for imageio-ffmpeg\n",
        "!pip install imageio==2.4.1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get OCSORT code"
      ],
      "metadata": {
        "id": "YizzdBUQhJua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ocsort\n",
        "%cd ocsort\n",
        "!wget https://raw.githubusercontent.com/noahcao/OC_SORT/master/trackers/ocsort_tracker/ocsort.py \n",
        "!wget https://raw.githubusercontent.com/noahcao/OC_SORT/master/trackers/ocsort_tracker/kalmanfilter.py \n",
        "!wget https://raw.githubusercontent.com/noahcao/OC_SORT/master/trackers/ocsort_tracker/association.py \n",
        "\n",
        "%cd .."
      ],
      "metadata": {
        "id": "vEm99f9QjUNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "lK2duJ_tl3ev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import filterpy\n",
        "\n",
        "import torch\n",
        "import super_gradients as sg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams[\"figure.figsize\"] = (20, 10)"
      ],
      "metadata": {
        "id": "fBNXLP7qUArx",
        "outputId": "e27dccef-495c-4764-91b8-6ca72c17db4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The console stream is logged into /root/sg_logs/console.log\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2023-05-11 00:10:10] INFO - crash_tips_setup.py - Crash tips is enabled. You can set your environment variable to CRASH_HANDLER=FALSE to disable it\n",
            "/usr/local/lib/python3.10/dist-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
            "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
            "[2023-05-11 00:10:18] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: matplotlib==3.1.3 does not satisfy requirement matplotlib>=3.3.4\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download video from YouTube"
      ],
      "metadata": {
        "id": "zEJO2FbwZVZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pytube import YouTube\n",
        "\n",
        "url =r\"https://www.youtube.com/watch?v=wIYD42DV3Ro\" # horse racing\n",
        "# url = r\"https://www.youtube.com/watch?v=JteKbauGolo\" # nascar\n",
        "yt = YouTube(url)\n",
        "print(\"Video Title: \", yt.title)\n",
        "\n",
        "# download video\n",
        "video_path = yt.streams \\\n",
        "  .filter(progressive=True, file_extension='mp4') \\\n",
        "  .order_by('resolution') \\\n",
        "  .desc() \\\n",
        "  .first() \\\n",
        "  .download()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EawjQ0FGYp0Q",
        "outputId": "60104c2d-879e-4221-ca18-065a1c16c155"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video Title:  Kentucky Derby 2022 (FULL RACE) | NBC Sports\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# horce racing\n",
        "video_savepath = 'derby.mp4'\n",
        "video_waudio_savepath = 'derby_with_audio.mp4'\n",
        "\n",
        "# nascar\n",
        "# video_savepath = 'chastain_wall_ride.mp4'\n",
        "# video_waudio_savepath = 'chastain_wall_ride_with_audio.mp4'"
      ],
      "metadata": {
        "id": "0LLCtVUQBmgA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instantiate YOLO-NAS model"
      ],
      "metadata": {
        "id": "O3AJIDUcZoXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from super_gradients.training import models\n",
        "\n",
        "model = models.get(\"yolo_nas_s\", pretrained_weights=\"coco\").cuda()\n",
        "model.eval();"
      ],
      "metadata": {
        "id": "1iQWTcJiZp4j"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantize model to increase inference speed\n",
        "THIS SEEMS to degrade speed from 15 FPS to 4 FPS)"
      ],
      "metadata": {
        "id": "pPlNAeOKHYv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from super_gradients.training.utils.quantization.selective_quantization_utils import SelectiveQuantizer\n",
        "\n",
        "# q_util = SelectiveQuantizer(\n",
        "#     default_quant_modules_calibrator_weights=\"max\",\n",
        "#     default_quant_modules_calibrator_inputs=\"histogram\",\n",
        "#     default_per_channel_quant_weights=True,\n",
        "#     default_learn_amax=False,\n",
        "#     verbose=True,\n",
        "# )\n",
        "# q_util.quantize_module(model)\n",
        "# model.to('cuda');\n",
        "# model.eval();"
      ],
      "metadata": {
        "id": "1s5S9Pf8FLKr"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check Model Inference Speed\n",
        "\n",
        "#### First get a test frame"
      ],
      "metadata": {
        "id": "TUmOXyTI0QC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(video_path)\n",
        "if (cap.isOpened() == False):\n",
        "    print(\"Error opening video file\")\n",
        "\n",
        "while(cap.isOpened()):\n",
        "\n",
        "  # read each video frame\n",
        "  ret, frame = cap.read()\n",
        "  frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  break\n",
        "\n",
        "cap.release()\n",
        "del cap"
      ],
      "metadata": {
        "id": "uyRduFZp0OnV"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Pipeline speed\n",
        "We will need to check the speed at which we can get the required inputs for the tracker."
      ],
      "metadata": {
        "id": "RY3e-AGhJgyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# baseline speed test to get detections for tracker\n",
        "image_in = frame.copy()\n",
        "base_test_times = []\n",
        "\n",
        "for i in range(100):\n",
        "  # start clock and rpedict\n",
        "  tic = time.perf_counter()\n",
        "  preds_0 = model.predict(image_in, iou=0.25, conf=0.30)\n",
        "  img_preds = list(preds_0._images_prediction_lst)[0]\n",
        "  dets = np.hstack((img_preds.prediction.bboxes_xyxy, \n",
        "                    np.c_[img_preds.prediction.confidence]))\n",
        "  base_test_times.append(time.perf_counter() - tic)\n",
        "\n",
        "print(f\"Average Prediction time: {np.mean(base_test_times)} \"\n",
        "      f\"Average FPS: {1/np.mean(base_test_times)}\")"
      ],
      "metadata": {
        "id": "Yy_gOo1L1Yl_"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.round(np.mean(base_test_times), 4), np.round(1/np.mean(base_test_times), 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2gicvth33EO",
        "outputId": "766320f5-bd33-4206-e588-f6e66436b353"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0605, 16.5362)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get new method of inference with reduced overhead. We can explore places in the API to leverage by finding where the predcit function is located. We can locate it with the inspect library.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "U-25MyOF4b8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "\n",
        "os.path.abspath(inspect.getfile(model.predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JnwQyDtE5RUi",
        "outputId": "7b2fe011-6d76-4643-87e0-25fb4445d720"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/usr/local/lib/python3.10/dist-packages/super_gradients/training/models/detection_models/customizable_detector.py'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from super_gradients.training.models.detection_models.customizable_detector import CustomizableDetector\n",
        "from super_gradients.training.pipelines.pipelines import DetectionPipeline\n",
        "\n",
        "# make sure to set IOU and confidence in the pipeline constructor\n",
        "pipeline = DetectionPipeline(\n",
        "            model=model,\n",
        "            image_processor=model._image_processor,\n",
        "            post_prediction_callback=model.get_post_prediction_callback(iou=0.25, conf=0.30),\n",
        "            class_names=model._class_names,\n",
        "        )\n",
        "\n",
        "\n",
        "def get_prediction(image_in, pipeline):\n",
        "  ''' Obtains DetectionPrediction object from a single input RGB image\n",
        "  '''\n",
        "  # Preprocess\n",
        "  preprocessed_image, processing_metadata = pipeline.image_processor.preprocess_image(image=image_in.copy())\n",
        "\n",
        "  # Predict\n",
        "  with torch.no_grad():\n",
        "      torch_input = torch.Tensor(preprocessed_image).unsqueeze(0).to('cuda')\n",
        "      model_output = model(torch_input)\n",
        "      prediction = pipeline._decode_model_output(model_output, model_input=torch_input)\n",
        "\n",
        "  # Postprocess\n",
        "  return pipeline.image_processor.postprocess_predictions(predictions=prediction[0], metadata=processing_metadata)"
      ],
      "metadata": {
        "id": "AGP-ExXQ2TLY"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_in = frame.copy()\n",
        "test_times = []\n",
        "\n",
        "for i in range(100):\n",
        "  # start clock and rpedict\n",
        "  tic = time.perf_counter()\n",
        "  pred = get_prediction(image_in, pipeline)\n",
        "  xyxyc = np.hstack((pred.bboxes_xyxy, \n",
        "                     np.c_[pred.confidence]))\n",
        "  test_times.append(time.perf_counter() - tic)\n",
        "\n",
        "print(f\"Average Prediction time: {np.mean(test_times)} \"\n",
        "      f\"Average FPS: {1/np.mean(test_times)}\")"
      ],
      "metadata": {
        "id": "kg4LbqnY7Hlo",
        "outputId": "63d70b2e-ce4c-460a-f14d-ea15d36a114a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Prediction time: 0.06047330899001281 Average FPS: 16.536220965933094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.round(np.mean(test_times), 4), np.round(1/np.mean(test_times), 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KLJXRkt7QQM",
        "outputId": "e4d738bd-b4a0-4492-d984-e1bbcaf94768"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0659, 15.1718)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bM83FOnS54RE",
        "outputId": "5599c9e0-0d57-480f-da59-803314682fa1"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DetectionPrediction(bboxes_xyxy=array([[1178.3569 ,  275.83493, 1218.6821 ,  383.23434],\n",
              "       [1232.7158 ,  262.42215, 1264.4724 ,  370.75522],\n",
              "       [1217.1113 ,  198.12184, 1253.5657 ,  253.76126],\n",
              "       [ 982.8118 ,  220.69008, 1010.603  ,  248.22868]], dtype=float32), confidence=array([0.6609424 , 0.555541  , 0.40006214, 0.3380518 ], dtype=float32), labels=array([ 0.,  0., 74.,  0.], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_preds.prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNCqDQDN6PMb",
        "outputId": "083ba544-74d5-414d-ae4c-e82ef7904f3b"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DetectionPrediction(bboxes_xyxy=array([[1178.3569 ,  275.83493, 1218.6821 ,  383.23434],\n",
              "       [1232.7158 ,  262.42215, 1264.4724 ,  370.75522],\n",
              "       [1217.1113 ,  198.12184, 1253.5657 ,  253.76126],\n",
              "       [ 982.8118 ,  220.69008, 1010.603  ,  248.22868]], dtype=float32), confidence=array([0.6609424 , 0.555541  , 0.40006214, 0.3380518 ], dtype=float32), labels=array([ 0.,  0., 74.,  0.], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perform inference on Simulated Video Stream\n",
        "\n",
        "#### First we will use MoviePy to get the frame rate and save the audio for later"
      ],
      "metadata": {
        "id": "YfcSFg7QZumm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "videoclip = VideoFileClip(video_path)\n",
        "audioclip = videoclip.audio\n",
        "\n",
        "video_fps = videoclip.fps\n",
        "video_fps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQrzaiCTZzPh",
        "outputId": "a6cf125f-4da1-478d-daca-5eef79d904e2"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29.97002997002997"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instantiate tracker object"
      ],
      "metadata": {
        "id": "04FGsaIPlGXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ocsort import ocsort\n",
        "\n",
        "tracker = ocsort.OCSort(det_thresh=0.25)"
      ],
      "metadata": {
        "id": "se9puRt3lJYC"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper function for bounding box colors"
      ],
      "metadata": {
        "id": "OkR9e1zBq0Ay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import colorsys    \n",
        "\n",
        "def get_color(number):\n",
        "    \"\"\" Converts an integer number to a color \"\"\"\n",
        "    # change these however you want to\n",
        "    hue = number*30 % 180\n",
        "    saturation = number*103 % 256\n",
        "    value = number*50 % 256\n",
        "\n",
        "    # expects normalized values\n",
        "    color = colorsys.hsv_to_rgb(hue/179, saturation/255, value/255)\n",
        "\n",
        "    return [int(c*255) for c in color]"
      ],
      "metadata": {
        "id": "ksE8TjoRqrid"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now we can simualate the data stream using opencv\n",
        "\n",
        "Make sure to reset the tracker each time you run the inference"
      ],
      "metadata": {
        "id": "1aFunGfzdqbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get frame info for tracker and video saving \n",
        "h, w = (720, 1280)\n",
        "h2, w2 = h//2, w//2\n",
        "# h2, w2 = 640, 640 # this degrades performance\n",
        "\n",
        "# OCSORT automatically rescales bboxes if we inference with a diff img size\n",
        "img_info = (h, w)\n",
        "img_size = (h2, w2) "
      ],
      "metadata": {
        "id": "wcOkR-KDl0dQ"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ensure tracker is reset\n",
        "tracker = ocsort.OCSort(det_thresh=0.30, max_age=10, min_hits=2)\n",
        "\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "if (cap.isOpened() == False):\n",
        "    print(\"Error opening video file\")\n",
        "\n",
        "frames = []\n",
        "i = 0\n",
        "counter, fps, elapsed = 0, 0, 0\n",
        "start_time = time.perf_counter()\n",
        "\n",
        "while(cap.isOpened()):\n",
        "\n",
        "  # read each video frame (read time is about 0.006 sec)\n",
        "  ret, frame = cap.read()\n",
        "\n",
        "  if ret == True:\n",
        "\n",
        "    # read image and resize by half for inference\n",
        "    og_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    frame = cv2.resize(og_frame, \n",
        "                       (w2, h2), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "    # perform inference on small frame and get (x1, y1, x2, y2, confidence)\n",
        "    pred = get_prediction(frame, pipeline)\n",
        "    xyxyc = np.hstack((pred.bboxes_xyxy, \n",
        "                      np.c_[pred.confidence]))\n",
        "\n",
        "    # update tracker\n",
        "    tracks = tracker.update(xyxyc, img_info, img_size)\n",
        "\n",
        "    # draw tracks on frame\n",
        "    for track in tracker.trackers:\n",
        "      \n",
        "      track_id = track.id\n",
        "      hits = track.hits\n",
        "      color = get_color(track_id*15)\n",
        "      x1,y1,x2,y2 = np.round(track.get_state()).astype(int).squeeze()\n",
        "\n",
        "      cv2.rectangle(og_frame, (x1,y1),(x2,y2), color, 2)\n",
        "      cv2.putText(og_frame, \n",
        "                  f\"{track_id}-{hits}\", \n",
        "                  (x1+10,y1-5), \n",
        "                  cv2.FONT_HERSHEY_SIMPLEX, \n",
        "                  0.5,\n",
        "                  color, \n",
        "                  1,\n",
        "                  cv2.LINE_AA)\n",
        "      \n",
        "    # update FPS and place on frame\n",
        "    current_time = time.perf_counter()\n",
        "    elapsed = (current_time - start_time)\n",
        "    counter += 1\n",
        "    if elapsed > 1:\n",
        "      fps = counter / elapsed;\n",
        "      counter = 0;\n",
        "      start_time = current_time;\n",
        "\n",
        "    cv2.putText(og_frame, \n",
        "                f\"FPS: {np.round(fps, 2)}\", \n",
        "                (10,h - 10), \n",
        "                cv2.FONT_HERSHEY_SIMPLEX, \n",
        "                1,\n",
        "                (255,255,255), \n",
        "                2,\n",
        "                cv2.LINE_AA)\n",
        "\n",
        "    # append to list\n",
        "    frames.append(og_frame)\n",
        "\n",
        "    # # TEMP for debug\n",
        "    # if i == 10:\n",
        "    #   break\n",
        "    # else:\n",
        "    #   i += 1\n",
        "\n",
        "  # Break the loop\n",
        "  else:\n",
        "    break\n",
        "\n",
        "# release video capture object\n",
        "cap.release()\n",
        "del cap"
      ],
      "metadata": {
        "id": "q112t7wldeHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(frames[450])"
      ],
      "metadata": {
        "id": "Y6WDBJ_vnv_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now let's put this in a video"
      ],
      "metadata": {
        "id": "ckO5TU4Us6zi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save to mp4\n",
        "out = cv2.VideoWriter(video_savepath,\n",
        "                      cv2.VideoWriter_fourcc(*'MP4V'), \n",
        "                      video_fps,\n",
        "                      (w, h))\n",
        " \n",
        "for frame in frames:\n",
        "    out.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "out.release()\n",
        "del out"
      ],
      "metadata": {
        "id": "3G2sb5YWs6gc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now add back the audio"
      ],
      "metadata": {
        "id": "rnvTeROgtXZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import CompositeAudioClip\n",
        "detection_video = VideoFileClip(video_savepath)\n",
        "\n",
        "# add sound and save\n",
        "detection_video.audio = CompositeAudioClip([audioclip])\n",
        "detection_video.write_videofile(video_waudio_savepath)"
      ],
      "metadata": {
        "id": "_5wQoICAtRzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RbIhrHeSBoNL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}